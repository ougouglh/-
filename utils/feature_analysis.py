import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import StratifiedKFold, cross_val_score
from sklearn.feature_selection import SelectKBest, chi2, f_classif, RFE
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import roc_auc_score
import lightgbm as lgb
import warnings
import json
import os
from datetime import datetime
from scipy.stats import pearsonr, spearmanr

# å°è¯•å¯¼å…¥é¢å¤–çš„åº“
try:
    import xgboost as xgb

    HAS_XGB = True
except ImportError:
    print("âš ï¸ æœªå®‰è£… XGBoost: pip install xgboost")
    HAS_XGB = False

try:
    from sklearn.inspection import permutation_importance

    HAS_PERM_IMP = True
except ImportError:
    print("âš ï¸ sklearnç‰ˆæœ¬è¾ƒä½ï¼Œæ— æ³•ä½¿ç”¨permutation_importance")
    HAS_PERM_IMP = False

warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡æ˜¾ç¤º
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False


class FeatureImportanceAnalyzer:
    """ç‰¹å¾é‡è¦æ€§åˆ†æå™¨"""

    def __init__(self, feature_dir='../outputs/features', output_dir='../outputs'):
        """
        åˆå§‹åŒ–åˆ†æå™¨

        Args:
            feature_dir: ç‰¹å¾æ–‡ä»¶ç›®å½•
            output_dir: è¾“å‡ºç›®å½•
        """
        self.feature_dir = feature_dir
        self.output_dir = output_dir

        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.analysis_dir = os.path.join(output_dir, 'feature_analysis')
        os.makedirs(self.analysis_dir, exist_ok=True)
        os.makedirs(os.path.join(self.analysis_dir, 'plots'), exist_ok=True)

        # æ•°æ®å®¹å™¨
        self.train_features = None
        self.test_features = None
        self.X_train = None
        self.y_train = None
        self.feature_names = None

        # ç»“æœå®¹å™¨
        self.importance_results = {}

        print(f"âœ… ç‰¹å¾é‡è¦æ€§åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.analysis_dir}")

    def load_features(self, timestamp=None):
        """åŠ è½½ç‰¹å¾æ–‡ä»¶"""
        print("ğŸ“Š åŠ è½½ç‰¹å¾æ–‡ä»¶...")

        # å¦‚æœæ²¡æœ‰æŒ‡å®šæ—¶é—´æˆ³ï¼Œæ‰¾æœ€æ–°çš„æ–‡ä»¶
        if timestamp is None:
            feature_files = [f for f in os.listdir(self.feature_dir) if
                             f.startswith('train_features_') and f.endswith('.csv')]
            if not feature_files:
                raise FileNotFoundError("æœªæ‰¾åˆ°ç‰¹å¾æ–‡ä»¶")

            # æ‰¾æœ€æ–°çš„æ–‡ä»¶
            latest_file = sorted(feature_files)[-1]
            timestamp = latest_file.replace('train_features_', '').replace('.csv', '')
            print(f"ğŸ” è‡ªåŠ¨é€‰æ‹©æœ€æ–°ç‰¹å¾æ–‡ä»¶: {timestamp}")

        # åŠ è½½ç‰¹å¾æ–‡ä»¶
        train_path = os.path.join(self.feature_dir, f'train_features_{timestamp}.csv')
        test_path = os.path.join(self.feature_dir, f'test_features_{timestamp}.csv')
        info_path = os.path.join(self.feature_dir, f'feature_info_{timestamp}.json')

        if not os.path.exists(train_path):
            raise FileNotFoundError(f"è®­ç»ƒç‰¹å¾æ–‡ä»¶ä¸å­˜åœ¨: {train_path}")

        # åŠ è½½è®­ç»ƒæ•°æ®
        self.train_features = pd.read_csv(train_path)
        print(f"âœ… è®­ç»ƒç‰¹å¾: {self.train_features.shape}")

        # åŠ è½½æµ‹è¯•æ•°æ®
        if os.path.exists(test_path):
            self.test_features = pd.read_csv(test_path)
            print(f"âœ… æµ‹è¯•ç‰¹å¾: {self.test_features.shape}")

        # åŠ è½½ç‰¹å¾ä¿¡æ¯
        if os.path.exists(info_path):
            with open(info_path, 'r', encoding='utf-8') as f:
                feature_info = json.load(f)
                self.feature_names = feature_info.get('feature_names', [])
                print(f"âœ… ç‰¹å¾ä¿¡æ¯: {len(self.feature_names)} ä¸ªç‰¹å¾")

        # å‡†å¤‡è®­ç»ƒæ•°æ®
        self._prepare_training_data()

    def _prepare_training_data(self):
        """å‡†å¤‡è®­ç»ƒæ•°æ®"""
        print("ğŸ”§ å‡†å¤‡è®­ç»ƒæ•°æ®...")

        # éœ€è¦åŠ è½½åŸå§‹è®­ç»ƒæ•°æ®æ¥è·å–æ ‡ç­¾
        train_original = pd.read_csv('../data/data_format1/train_format1.csv')

        # åˆå¹¶ç‰¹å¾å’Œæ ‡ç­¾
        train_data = self.train_features.merge(
            train_original[['user_id', 'merchant_id', 'label']],
            on=['user_id', 'merchant_id'],
            how='left'
        )

        # å‡†å¤‡Xå’Œy
        feature_cols = [col for col in train_data.columns
                        if col not in ['user_id', 'merchant_id', 'label']]

        self.X_train = train_data[feature_cols]
        self.y_train = train_data['label']

        if self.feature_names is None:
            self.feature_names = feature_cols

        print(f"âœ… è®­ç»ƒæ•°æ®å‡†å¤‡å®Œæˆ: X{self.X_train.shape}, y{self.y_train.shape}")
        print(f"ğŸ“Š æ­£æ ·æœ¬æ¯”ä¾‹: {self.y_train.mean() * 100:.2f}%")

    def correlation_analysis(self):
        """ç›¸å…³æ€§åˆ†æ"""
        print("\nğŸ“ˆ å¼€å§‹ç›¸å…³æ€§åˆ†æ...")

        # è®¡ç®—ä¸ç›®æ ‡å˜é‡çš„ç›¸å…³æ€§
        correlations = {}

        for col in self.X_train.columns:
            try:
                # Pearsonç›¸å…³ç³»æ•°
                pearson_corr, pearson_p = pearsonr(self.X_train[col], self.y_train)

                # Spearmanç›¸å…³ç³»æ•°
                spearman_corr, spearman_p = spearmanr(self.X_train[col], self.y_train)

                correlations[col] = {
                    'pearson_corr': pearson_corr,
                    'pearson_p_value': pearson_p,
                    'spearman_corr': spearman_corr,
                    'spearman_p_value': spearman_p,
                    'abs_pearson': abs(pearson_corr),
                    'abs_spearman': abs(spearman_corr)
                }
            except Exception as e:
                print(f"  âš ï¸ è®¡ç®— {col} ç›¸å…³æ€§å¤±è´¥: {e}")
                correlations[col] = {
                    'pearson_corr': 0, 'pearson_p_value': 1,
                    'spearman_corr': 0, 'spearman_p_value': 1,
                    'abs_pearson': 0, 'abs_spearman': 0
                }

        # è½¬æ¢ä¸ºDataFrameå¹¶æ’åº
        corr_df = pd.DataFrame(correlations).T
        corr_df = corr_df.sort_values('abs_pearson', ascending=False)

        self.importance_results['correlation'] = corr_df

        # æ˜¾ç¤ºTOPç‰¹å¾
        print(f"\nğŸ¯ ç›¸å…³æ€§åˆ†æç»“æœ (TOP 10):")
        for i, (feature, data) in enumerate(corr_df.head(10).iterrows()):
            print(
                f"  {i + 1:2d}. {feature:30s} | Pearson: {data['pearson_corr']:6.3f} | Spearman: {data['spearman_corr']:6.3f}")

        # å¯è§†åŒ–
        self._plot_correlation_analysis(corr_df)

        return corr_df

    def _plot_correlation_analysis(self, corr_df):
        """å¯è§†åŒ–ç›¸å…³æ€§åˆ†æ"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))

        # TOP 15ç›¸å…³æ€§ç‰¹å¾
        top_features = corr_df.head(15)

        # Pearsonç›¸å…³æ€§
        axes[0, 0].barh(range(len(top_features)), top_features['pearson_corr'])
        axes[0, 0].set_yticks(range(len(top_features)))
        axes[0, 0].set_yticklabels(top_features.index, fontsize=8)
        axes[0, 0].set_title('TOP 15 Pearsonç›¸å…³æ€§')
        axes[0, 0].set_xlabel('ç›¸å…³ç³»æ•°')

        # Spearmanç›¸å…³æ€§
        axes[0, 1].barh(range(len(top_features)), top_features['spearman_corr'])
        axes[0, 1].set_yticks(range(len(top_features)))
        axes[0, 1].set_yticklabels(top_features.index, fontsize=8)
        axes[0, 1].set_title('TOP 15 Spearmanç›¸å…³æ€§')
        axes[0, 1].set_xlabel('ç›¸å…³ç³»æ•°')

        # ç»å¯¹ç›¸å…³æ€§å¯¹æ¯”
        axes[1, 0].scatter(top_features['abs_pearson'], top_features['abs_spearman'], alpha=0.7)
        axes[1, 0].plot([0, top_features['abs_pearson'].max()], [0, top_features['abs_pearson'].max()], 'r--',
                        alpha=0.5)
        axes[1, 0].set_xlabel('ç»å¯¹Pearsonç›¸å…³æ€§')
        axes[1, 0].set_ylabel('ç»å¯¹Spearmanç›¸å…³æ€§')
        axes[1, 0].set_title('çº¿æ€§ vs å•è°ƒç›¸å…³æ€§')

        # ç›¸å…³æ€§åˆ†å¸ƒ
        axes[1, 1].hist(corr_df['pearson_corr'], bins=30, alpha=0.7, label='Pearson')
        axes[1, 1].hist(corr_df['spearman_corr'], bins=30, alpha=0.7, label='Spearman')
        axes[1, 1].set_xlabel('ç›¸å…³ç³»æ•°')
        axes[1, 1].set_ylabel('ç‰¹å¾æ•°é‡')
        axes[1, 1].set_title('ç›¸å…³æ€§åˆ†å¸ƒ')
        axes[1, 1].legend()

        plt.tight_layout()
        plot_path = os.path.join(self.analysis_dir, 'plots', 'correlation_analysis.png')
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        plt.show()
        print(f"ğŸ“Š ç›¸å…³æ€§åˆ†æå›¾å·²ä¿å­˜: {plot_path}")

    def statistical_feature_selection(self):
        """ç»Ÿè®¡ç‰¹å¾é€‰æ‹©"""
        print("\nğŸ“Š å¼€å§‹ç»Ÿè®¡ç‰¹å¾é€‰æ‹©...")

        results = {}

        # 1. å¡æ–¹æ£€éªŒ (é€‚ç”¨äºéè´Ÿç‰¹å¾)
        try:
            # ç¡®ä¿ç‰¹å¾éè´Ÿ
            X_non_negative = self.X_train.copy()
            for col in X_non_negative.columns:
                if X_non_negative[col].min() < 0:
                    X_non_negative[col] = X_non_negative[col] - X_non_negative[col].min()

            chi2_selector = SelectKBest(chi2, k='all')
            chi2_selector.fit(X_non_negative, self.y_train)

            chi2_scores = pd.DataFrame({
                'feature': self.X_train.columns,
                'chi2_score': chi2_selector.scores_,
                'chi2_p_value': chi2_selector.pvalues_
            }).sort_values('chi2_score', ascending=False)

            results['chi2'] = chi2_scores
            print("âœ… å¡æ–¹æ£€éªŒå®Œæˆ")

        except Exception as e:
            print(f"âš ï¸ å¡æ–¹æ£€éªŒå¤±è´¥: {e}")

        # 2. Fæ£€éªŒ
        try:
            f_selector = SelectKBest(f_classif, k='all')
            f_selector.fit(self.X_train, self.y_train)

            f_scores = pd.DataFrame({
                'feature': self.X_train.columns,
                'f_score': f_selector.scores_,
                'f_p_value': f_selector.pvalues_
            }).sort_values('f_score', ascending=False)

            results['f_test'] = f_scores
            print("âœ… Fæ£€éªŒå®Œæˆ")

        except Exception as e:
            print(f"âš ï¸ Fæ£€éªŒå¤±è´¥: {e}")

        self.importance_results['statistical'] = results

        # æ˜¾ç¤ºç»“æœ
        if 'f_test' in results:
            print(f"\nğŸ¯ Fæ£€éªŒç»“æœ (TOP 10):")
            for i, (_, row) in enumerate(results['f_test'].head(10).iterrows()):
                print(
                    f"  {i + 1:2d}. {row['feature']:30s} | F-score: {row['f_score']:8.2f} | p-value: {row['f_p_value']:.2e}")

        return results

    def model_based_importance(self):
        """åŸºäºæ¨¡å‹çš„ç‰¹å¾é‡è¦æ€§"""
        print("\nğŸ¤– å¼€å§‹åŸºäºæ¨¡å‹çš„ç‰¹å¾é‡è¦æ€§åˆ†æ...")

        results = {}

        # 1. Random Forest
        print("  ğŸŒ³ Random Forest...")
        try:
            rf = RandomForestClassifier(
                n_estimators=100,
                random_state=42,
                class_weight='balanced',  # å¤„ç†ç±»åˆ«ä¸å¹³è¡¡
                n_jobs=-1
            )
            rf.fit(self.X_train, self.y_train)

            rf_importance = pd.DataFrame({
                'feature': self.X_train.columns,
                'importance': rf.feature_importances_
            }).sort_values('importance', ascending=False)

            results['random_forest'] = rf_importance
            print("    âœ… Random Forestå®Œæˆ")

        except Exception as e:
            print(f"    âŒ Random Forestå¤±è´¥: {e}")

        # 2. LightGBM
        print("  ğŸ’¡ LightGBM...")
        try:
            # åˆ›å»ºLightGBMæ•°æ®é›†
            train_data = lgb.Dataset(self.X_train, label=self.y_train)

            # å‚æ•°è®¾ç½®
            params = {
                'objective': 'binary',
                'metric': 'auc',
                'boosting_type': 'gbdt',
                'num_leaves': 31,
                'learning_rate': 0.1,
                'feature_fraction': 0.9,
                'bagging_fraction': 0.8,
                'bagging_freq': 5,
                'verbose': -1,
                'is_unbalance': True  # å¤„ç†ç±»åˆ«ä¸å¹³è¡¡
            }

            # è®­ç»ƒæ¨¡å‹
            lgb_model = lgb.train(
                params,
                train_data,
                num_boost_round=100,
                valid_sets=[train_data],
                callbacks=[lgb.early_stopping(10), lgb.log_evaluation(0)]
            )

            # è·å–ç‰¹å¾é‡è¦æ€§
            lgb_importance = pd.DataFrame({
                'feature': self.X_train.columns,
                'importance': lgb_model.feature_importance(importance_type='gain'),
                'split_importance': lgb_model.feature_importance(importance_type='split')
            }).sort_values('importance', ascending=False)

            results['lightgbm'] = lgb_importance
            print("    âœ… LightGBMå®Œæˆ")

        except Exception as e:
            print(f"    âŒ LightGBMå¤±è´¥: {e}")

        # 3. XGBoost (å¦‚æœå¯ç”¨)
        if HAS_XGB:
            print("  ğŸš€ XGBoost...")
            try:
                xgb_model = xgb.XGBClassifier(
                    n_estimators=100,
                    random_state=42,
                    scale_pos_weight=len(self.y_train[self.y_train == 0]) / len(self.y_train[self.y_train == 1]),
                    # å¤„ç†ä¸å¹³è¡¡
                    n_jobs=-1
                )
                xgb_model.fit(self.X_train, self.y_train)

                xgb_importance = pd.DataFrame({
                    'feature': self.X_train.columns,
                    'importance': xgb_model.feature_importances_
                }).sort_values('importance', ascending=False)

                results['xgboost'] = xgb_importance
                print("    âœ… XGBoostå®Œæˆ")

            except Exception as e:
                print(f"    âŒ XGBoostå¤±è´¥: {e}")

        # 4. é€’å½’ç‰¹å¾æ¶ˆé™¤ (RFE)
        print("  ğŸ”„ é€’å½’ç‰¹å¾æ¶ˆé™¤...")
        try:
            # ä½¿ç”¨é€»è¾‘å›å½’ä½œä¸ºåŸºç¡€ä¼°è®¡å™¨
            lr = LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000)

            # é€‰æ‹©TOP 30ç‰¹å¾
            rfe = RFE(estimator=lr, n_features_to_select=30, step=1)
            rfe.fit(self.X_train, self.y_train)

            rfe_results = pd.DataFrame({
                'feature': self.X_train.columns,
                'selected': rfe.support_,
                'ranking': rfe.ranking_
            }).sort_values('ranking')

            results['rfe'] = rfe_results
            print("    âœ… é€’å½’ç‰¹å¾æ¶ˆé™¤å®Œæˆ")

        except Exception as e:
            print(f"    âŒ é€’å½’ç‰¹å¾æ¶ˆé™¤å¤±è´¥: {e}")

        self.importance_results['model_based'] = results

        # æ˜¾ç¤ºç»“æœ
        if 'lightgbm' in results:
            print(f"\nğŸ¯ LightGBMç‰¹å¾é‡è¦æ€§ (TOP 10):")
            for i, (_, row) in enumerate(results['lightgbm'].head(10).iterrows()):
                print(f"  {i + 1:2d}. {row['feature']:30s} | é‡è¦æ€§: {row['importance']:8.2f}")

        # å¯è§†åŒ–
        self._plot_model_importance(results)

        return results

    def _plot_model_importance(self, results):
        """å¯è§†åŒ–æ¨¡å‹é‡è¦æ€§"""
        n_models = len(results)
        if n_models == 0:
            return

        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        axes = axes.flatten()

        plot_idx = 0

        for model_name, importance_df in results.items():
            if plot_idx >= 4:
                break

            if model_name == 'rfe':
                # RFEç»“æœç‰¹æ®Šå¤„ç†
                selected_features = importance_df[importance_df['selected']].head(15)
                axes[plot_idx].barh(range(len(selected_features)), [1] * len(selected_features))
                axes[plot_idx].set_yticks(range(len(selected_features)))
                axes[plot_idx].set_yticklabels(selected_features['feature'], fontsize=8)
                axes[plot_idx].set_title(f'{model_name.upper()} é€‰ä¸­ç‰¹å¾')
            else:
                # å…¶ä»–æ¨¡å‹çš„é‡è¦æ€§
                top_features = importance_df.head(15)
                importance_col = 'importance' if 'importance' in importance_df.columns else importance_df.columns[1]

                axes[plot_idx].barh(range(len(top_features)), top_features[importance_col])
                axes[plot_idx].set_yticks(range(len(top_features)))
                axes[plot_idx].set_yticklabels(top_features['feature'], fontsize=8)
                axes[plot_idx].set_title(f'{model_name.upper()} ç‰¹å¾é‡è¦æ€§')
                axes[plot_idx].set_xlabel('é‡è¦æ€§å¾—åˆ†')

            plot_idx += 1

        # éšè—æœªä½¿ç”¨çš„å­å›¾
        for i in range(plot_idx, 4):
            axes[i].set_visible(False)

        plt.tight_layout()
        plot_path = os.path.join(self.analysis_dir, 'plots', 'model_importance.png')
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        plt.show()
        print(f"ğŸ“Š æ¨¡å‹é‡è¦æ€§å›¾å·²ä¿å­˜: {plot_path}")

    def permutation_importance_analysis(self):
        """æ’åˆ—é‡è¦æ€§åˆ†æ"""
        if not HAS_PERM_IMP:
            print("âš ï¸ sklearnç‰ˆæœ¬ä¸æ”¯æŒpermutation_importanceï¼Œè·³è¿‡")
            return None

        print("\nğŸ”€ å¼€å§‹æ’åˆ—é‡è¦æ€§åˆ†æ...")

        try:
            # ä½¿ç”¨LightGBMæ¨¡å‹
            lgb_model = lgb.LGBMClassifier(
                n_estimators=50,  # å‡å°‘æ ‘çš„æ•°é‡ä»¥åŠ é€Ÿ
                random_state=42,
                is_unbalance=True,
                verbose=-1
            )
            lgb_model.fit(self.X_train, self.y_train)

            # è®¡ç®—æ’åˆ—é‡è¦æ€§
            perm_importance = permutation_importance(
                lgb_model, self.X_train, self.y_train,
                n_repeats=5,  # é‡å¤æ¬¡æ•°
                random_state=42,
                scoring='roc_auc'
            )

            # æ•´ç†ç»“æœ
            perm_results = pd.DataFrame({
                'feature': self.X_train.columns,
                'importance_mean': perm_importance.importances_mean,
                'importance_std': perm_importance.importances_std
            }).sort_values('importance_mean', ascending=False)

            self.importance_results['permutation'] = perm_results

            print(f"ğŸ¯ æ’åˆ—é‡è¦æ€§åˆ†æç»“æœ (TOP 10):")
            for i, (_, row) in enumerate(perm_results.head(10).iterrows()):
                print(
                    f"  {i + 1:2d}. {row['feature']:30s} | é‡è¦æ€§: {row['importance_mean']:6.4f} Â± {row['importance_std']:6.4f}")

            return perm_results

        except Exception as e:
            print(f"âŒ æ’åˆ—é‡è¦æ€§åˆ†æå¤±è´¥: {e}")
            return None

    def feature_stability_analysis(self):
        """ç‰¹å¾ç¨³å®šæ€§åˆ†æ"""
        print("\nğŸ”„ å¼€å§‹ç‰¹å¾ç¨³å®šæ€§åˆ†æ...")

        try:
            # ä½¿ç”¨äº¤å‰éªŒè¯è¯„ä¼°ç‰¹å¾ç¨³å®šæ€§
            skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

            stability_results = {}

            for fold, (train_idx, val_idx) in enumerate(skf.split(self.X_train, self.y_train)):
                print(f"  ğŸ“Š å¤„ç†ç¬¬ {fold + 1} æŠ˜...")

                X_fold = self.X_train.iloc[train_idx]
                y_fold = self.y_train.iloc[train_idx]

                # è®­ç»ƒLightGBM
                lgb_model = lgb.LGBMClassifier(
                    n_estimators=50,
                    random_state=42,
                    is_unbalance=True,
                    verbose=-1
                )
                lgb_model.fit(X_fold, y_fold)

                # è®°å½•ç‰¹å¾é‡è¦æ€§
                for i, feature in enumerate(self.X_train.columns):
                    if feature not in stability_results:
                        stability_results[feature] = []
                    stability_results[feature].append(lgb_model.feature_importances_[i])

            # è®¡ç®—ç¨³å®šæ€§æŒ‡æ ‡
            stability_df = pd.DataFrame({
                'feature': list(stability_results.keys()),
                'mean_importance': [np.mean(scores) for scores in stability_results.values()],
                'std_importance': [np.std(scores) for scores in stability_results.values()],
                'cv_importance': [np.std(scores) / np.mean(scores) if np.mean(scores) > 0 else float('inf')
                                  for scores in stability_results.values()]
            })

            # æŒ‰å¹³å‡é‡è¦æ€§æ’åº
            stability_df = stability_df.sort_values('mean_importance', ascending=False)

            self.importance_results['stability'] = stability_df

            print(f"ğŸ¯ ç‰¹å¾ç¨³å®šæ€§åˆ†æç»“æœ (TOP 10):")
            for i, (_, row) in enumerate(stability_df.head(10).iterrows()):
                print(
                    f"  {i + 1:2d}. {row['feature']:30s} | å¹³å‡: {row['mean_importance']:6.4f} | CV: {row['cv_importance']:6.4f}")

            return stability_df

        except Exception as e:
            print(f"âŒ ç‰¹å¾ç¨³å®šæ€§åˆ†æå¤±è´¥: {e}")
            return None

    def comprehensive_feature_ranking(self):
        """ç»¼åˆç‰¹å¾æ’å"""
        print("\nğŸ† å¼€å§‹ç»¼åˆç‰¹å¾æ’å...")

        # æ”¶é›†æ‰€æœ‰å¯ç”¨çš„é‡è¦æ€§ç»“æœ
        ranking_data = {}

        # åˆå§‹åŒ–ç‰¹å¾åˆ—è¡¨
        for feature in self.X_train.columns:
            ranking_data[feature] = {'scores': [], 'methods': []}

        # 1. ç›¸å…³æ€§åˆ†æ
        if 'correlation' in self.importance_results:
            corr_df = self.importance_results['correlation']
            for feature in corr_df.index:
                if feature in ranking_data:
                    # ä½¿ç”¨ç»å¯¹ç›¸å…³æ€§ä½œä¸ºå¾—åˆ†
                    score = corr_df.loc[feature, 'abs_pearson']
                    ranking_data[feature]['scores'].append(score)
                    ranking_data[feature]['methods'].append('correlation')

        # 2. æ¨¡å‹é‡è¦æ€§
        if 'model_based' in self.importance_results:
            for model_name, importance_df in self.importance_results['model_based'].items():
                if model_name == 'rfe':
                    # RFEç‰¹æ®Šå¤„ç†ï¼šé€‰ä¸­çš„ç‰¹å¾å¾—åˆ†ä¸º1ï¼Œæœªé€‰ä¸­ä¸º0
                    for _, row in importance_df.iterrows():
                        feature = row['feature']
                        if feature in ranking_data:
                            score = 1.0 if row['selected'] else 0.0
                            ranking_data[feature]['scores'].append(score)
                            ranking_data[feature]['methods'].append(f'rfe')
                else:
                    # æ ‡å‡†åŒ–é‡è¦æ€§å¾—åˆ†
                    importance_col = 'importance' if 'importance' in importance_df.columns else importance_df.columns[1]
                    max_importance = importance_df[importance_col].max()

                    for _, row in importance_df.iterrows():
                        feature = row['feature']
                        if feature in ranking_data and max_importance > 0:
                            score = row[importance_col] / max_importance
                            ranking_data[feature]['scores'].append(score)
                            ranking_data[feature]['methods'].append(f'model_{model_name}')

        # 3. æ’åˆ—é‡è¦æ€§
        if 'permutation' in self.importance_results:
            perm_df = self.importance_results['permutation']
            max_perm = perm_df['importance_mean'].max()
            if max_perm > 0:
                for _, row in perm_df.iterrows():
                    feature = row['feature']
                    if feature in ranking_data:
                        score = row['importance_mean'] / max_perm
                        ranking_data[feature]['scores'].append(score)
                        ranking_data[feature]['methods'].append('permutation')

        # 4. ç¨³å®šæ€§åˆ†æ
        if 'stability' in self.importance_results:
            stability_df = self.importance_results['stability']
            max_stability = stability_df['mean_importance'].max()
            if max_stability > 0:
                for _, row in stability_df.iterrows():
                    feature = row['feature']
                    if feature in ranking_data:
                        score = row['mean_importance'] / max_stability
                        ranking_data[feature]['scores'].append(score)
                        ranking_data[feature]['methods'].append('stability')

        # è®¡ç®—ç»¼åˆå¾—åˆ†
        comprehensive_results = []
        for feature, data in ranking_data.items():
            if data['scores']:
                mean_score = np.mean(data['scores'])
                std_score = np.std(data['scores']) if len(data['scores']) > 1 else 0
                method_count = len(data['scores'])

                comprehensive_results.append({
                    'feature': feature,
                    'ç»¼åˆå¾—åˆ†': mean_score,
                    'å¾—åˆ†æ ‡å‡†å·®': std_score,
                    'æ–¹æ³•æ•°é‡': method_count,
                    'ç¨³å®šæ€§': 1 - (std_score / mean_score if mean_score > 0 else 1),
                    'æ–¹æ³•åˆ—è¡¨': ', '.join(data['methods'])
                })

        # è½¬æ¢ä¸ºDataFrameå¹¶æ’åº
        final_ranking = pd.DataFrame(comprehensive_results)
        final_ranking = final_ranking.sort_values('ç»¼åˆå¾—åˆ†', ascending=False)

        self.importance_results['comprehensive'] = final_ranking

        # æ˜¾ç¤ºTOPç‰¹å¾
        print(f"ğŸ¯ ç»¼åˆç‰¹å¾æ’å (TOP 15):")
        print(f"{'æ’å':>4} {'ç‰¹å¾å':30} {'ç»¼åˆå¾—åˆ†':>8} {'ç¨³å®šæ€§':>8} {'æ–¹æ³•æ•°':>6}")
        print("-" * 70)

        for i, (_, row) in enumerate(final_ranking.head(15).iterrows()):
            print(f"{i + 1:4d} {row['feature']:30} {row['ç»¼åˆå¾—åˆ†']:8.4f} {row['ç¨³å®šæ€§']:8.4f} {row['æ–¹æ³•æ•°é‡']:6d}")

        # å¯è§†åŒ–ç»¼åˆæ’å
        self._plot_comprehensive_ranking(final_ranking)

        return final_ranking

    def _plot_comprehensive_ranking(self, ranking_df):
        """å¯è§†åŒ–ç»¼åˆæ’å"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))

        # TOP 15ç‰¹å¾ç»¼åˆå¾—åˆ†
        top_15 = ranking_df.head(15)

        axes[0, 0].barh(range(len(top_15)), top_15['ç»¼åˆå¾—åˆ†'])
        axes[0, 0].set_yticks(range(len(top_15)))
        axes[0, 0].set_yticklabels(top_15['feature'], fontsize=8)
        axes[0, 0].set_title('TOP 15 ç»¼åˆç‰¹å¾é‡è¦æ€§')
        axes[0, 0].set_xlabel('ç»¼åˆå¾—åˆ†')

        # ç¨³å®šæ€§ vs é‡è¦æ€§æ•£ç‚¹å›¾
        axes[0, 1].scatter(ranking_df['ç»¼åˆå¾—åˆ†'], ranking_df['ç¨³å®šæ€§'], alpha=0.6)
        axes[0, 1].set_xlabel('ç»¼åˆå¾—åˆ†')
        axes[0, 1].set_ylabel('ç¨³å®šæ€§')
        axes[0, 1].set_title('é‡è¦æ€§ vs ç¨³å®šæ€§')

        # æ–¹æ³•æ•°é‡åˆ†å¸ƒ
        method_counts = ranking_df['æ–¹æ³•æ•°é‡'].value_counts().sort_index()
        axes[1, 0].bar(method_counts.index, method_counts.values)
        axes[1, 0].set_xlabel('ä½¿ç”¨çš„æ–¹æ³•æ•°é‡')
        axes[1, 0].set_ylabel('ç‰¹å¾æ•°é‡')
        axes[1, 0].set_title('ç‰¹å¾è¯„ä¼°æ–¹æ³•æ•°é‡åˆ†å¸ƒ')

        # ç»¼åˆå¾—åˆ†åˆ†å¸ƒ
        axes[1, 1].hist(ranking_df['ç»¼åˆå¾—åˆ†'], bins=20, alpha=0.7)
        axes[1, 1].set_xlabel('ç»¼åˆå¾—åˆ†')
        axes[1, 1].set_ylabel('ç‰¹å¾æ•°é‡')
        axes[1, 1].set_title('ç»¼åˆå¾—åˆ†åˆ†å¸ƒ')

        plt.tight_layout()
        plot_path = os.path.join(self.analysis_dir, 'plots', 'comprehensive_ranking.png')
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        plt.show()
        print(f"ğŸ“Š ç»¼åˆæ’åå›¾å·²ä¿å­˜: {plot_path}")

    def feature_selection_recommendation(self, top_k=30):
        """ç‰¹å¾é€‰æ‹©å»ºè®®"""
        print(f"\nğŸ’¡ ç‰¹å¾é€‰æ‹©å»ºè®® (æ¨èTOP {top_k}ç‰¹å¾)...")

        if 'comprehensive' in self.importance_results:
            comprehensive_ranking = self.importance_results['comprehensive']

            # åŸºäºç»¼åˆå¾—åˆ†é€‰æ‹©TOPç‰¹å¾
            recommended_features = comprehensive_ranking.head(top_k)['feature'].tolist()

            # ç‰¹å¾ç±»å‹åˆ†æ
            feature_types = {
                'user_features': [f for f in recommended_features if f.startswith('user_')],
                'merchant_features': [f for f in recommended_features if f.startswith('merchant_')],
                'behavior_features': [f for f in recommended_features if
                                      any(x in f for x in ['action_', 'total_actions', 'unique_'])],
                'cross_features': [f for f in recommended_features if '_x_' in f or 'relative' in f],
                'other_features': [f for f in recommended_features if not any(
                    x in f for x in ['user_', 'merchant_', 'action_', 'total_actions', 'unique_', '_x_', 'relative'])]
            }

            print(f"ğŸ“Š æ¨èç‰¹å¾åˆ†å¸ƒ:")
            for feature_type, features in feature_types.items():
                if features:
                    print(f"  {feature_type:20}: {len(features):2d}ä¸ª")

            print(f"\nğŸ¯ TOP {top_k} æ¨èç‰¹å¾:")
            for i, feature in enumerate(recommended_features):
                score = comprehensive_ranking[comprehensive_ranking['feature'] == feature]['ç»¼åˆå¾—åˆ†'].iloc[0]
                print(f"  {i + 1:2d}. {feature:35} (å¾—åˆ†: {score:.4f})")

            # ä¿å­˜æ¨èåˆ—è¡¨
            recommendation = {
                'timestamp': datetime.now().isoformat(),
                'top_k': top_k,
                'recommended_features': recommended_features,
                'feature_type_distribution': {k: len(v) for k, v in feature_types.items()},
                'comprehensive_scores': comprehensive_ranking.head(top_k).to_dict('records')
            }

            rec_path = os.path.join(self.analysis_dir, f'feature_recommendation_top{top_k}.json')
            with open(rec_path, 'w', encoding='utf-8') as f:
                json.dump(recommendation, f, ensure_ascii=False, indent=2)

            print(f"ğŸ’¾ ç‰¹å¾æ¨èå·²ä¿å­˜: {rec_path}")

            return recommended_features
        else:
            print("âš ï¸ éœ€è¦å…ˆè¿è¡Œç»¼åˆç‰¹å¾æ’ååˆ†æ")
            return None

    def generate_analysis_report(self):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        print("\nğŸ“‹ ç”Ÿæˆç‰¹å¾é‡è¦æ€§åˆ†ææŠ¥å‘Š...")

        report = {
            'analysis_timestamp': datetime.now().isoformat(),
            'data_summary': {
                'train_samples': len(self.X_train),
                'feature_count': len(self.X_train.columns),
                'positive_rate': float(self.y_train.mean()),
                'feature_names': list(self.X_train.columns)
            },
            'analysis_methods': list(self.importance_results.keys()),
            'top_features_by_method': {}
        }

        # æ”¶é›†å„æ–¹æ³•çš„TOPç‰¹å¾
        for method, results in self.importance_results.items():
            if method == 'correlation':
                top_features = results.head(10).index.tolist()
                report['top_features_by_method'][method] = top_features
            elif method == 'model_based':
                for model_name, model_results in results.items():
                    if model_name != 'rfe':
                        importance_col = 'importance' if 'importance' in model_results.columns else \
                        model_results.columns[1]
                        top_features = model_results.head(10)['feature'].tolist()
                        report['top_features_by_method'][f'{method}_{model_name}'] = top_features
            elif method in ['permutation', 'stability', 'comprehensive']:
                if isinstance(results, pd.DataFrame) and 'feature' in results.columns:
                    top_features = results.head(10)['feature'].tolist()
                    report['top_features_by_method'][method] = top_features

        # ä¿å­˜æŠ¥å‘Š
        report_path = os.path.join(self.analysis_dir, 'feature_importance_report.json')
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

        print(f"âœ… åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {report_path}")

        # ç”ŸæˆREADME
        self._generate_readme()

        return report

    def _generate_readme(self):
        """ç”ŸæˆREADMEæ–‡ä»¶"""
        readme_content = f"""# ç‰¹å¾é‡è¦æ€§åˆ†ææŠ¥å‘Š

## åˆ†ææ¦‚è¿°
- **åˆ†ææ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **æ•°æ®è§„æ¨¡**: {len(self.X_train):,} æ ·æœ¬ Ã— {len(self.X_train.columns)} ç‰¹å¾
- **æ­£æ ·æœ¬æ¯”ä¾‹**: {self.y_train.mean() * 100:.2f}%

## åˆ†ææ–¹æ³•
"""

        if 'correlation' in self.importance_results:
            readme_content += "âœ… ç›¸å…³æ€§åˆ†æ (Pearson & Spearman)\n"
        if 'statistical' in self.importance_results:
            readme_content += "âœ… ç»Ÿè®¡æ£€éªŒ (å¡æ–¹æ£€éªŒ & Fæ£€éªŒ)\n"
        if 'model_based' in self.importance_results:
            readme_content += "âœ… æ¨¡å‹é‡è¦æ€§ (Random Forest, LightGBM, XGBoost)\n"
        if 'permutation' in self.importance_results:
            readme_content += "âœ… æ’åˆ—é‡è¦æ€§åˆ†æ\n"
        if 'stability' in self.importance_results:
            readme_content += "âœ… ç‰¹å¾ç¨³å®šæ€§åˆ†æ\n"
        if 'comprehensive' in self.importance_results:
            readme_content += "âœ… ç»¼åˆç‰¹å¾æ’å\n"

        readme_content += f"""
## å…³é”®å‘ç°

### TOP 10 é‡è¦ç‰¹å¾
"""

        if 'comprehensive' in self.importance_results:
            top_features = self.importance_results['comprehensive'].head(10)
            for i, (_, row) in enumerate(top_features.iterrows()):
                readme_content += f"{i + 1}. **{row['feature']}** (å¾—åˆ†: {row['ç»¼åˆå¾—åˆ†']:.4f})\n"

        readme_content += f"""
## æ–‡ä»¶è¯´æ˜
- `plots/`: æ‰€æœ‰åˆ†æå›¾è¡¨
- `feature_importance_report.json`: å®Œæ•´åˆ†æç»“æœ
- `feature_recommendation_top30.json`: ç‰¹å¾é€‰æ‹©å»ºè®®

## å»ºè®®
åŸºäºåˆ†æç»“æœï¼Œå»ºè®®åœ¨æ¨¡å‹è®­ç»ƒä¸­ä¼˜å…ˆä½¿ç”¨TOP 30ç‰¹å¾ï¼Œå¯ä»¥åœ¨ä¿æŒæ€§èƒ½çš„åŒæ—¶é™ä½æ¨¡å‹å¤æ‚åº¦ã€‚

---
ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""

        readme_path = os.path.join(self.analysis_dir, 'README.md')
        with open(readme_path, 'w', encoding='utf-8') as f:
            f.write(readme_content)

        print(f"ğŸ“– READMEå·²ä¿å­˜: {readme_path}")

    def run_full_analysis(self, top_k=30):
        """è¿è¡Œå®Œæ•´åˆ†ææµç¨‹"""
        print("ğŸš€ å¼€å§‹å®Œæ•´ç‰¹å¾é‡è¦æ€§åˆ†æ...")

        # 1. ç›¸å…³æ€§åˆ†æ
        self.correlation_analysis()

        # 2. ç»Ÿè®¡ç‰¹å¾é€‰æ‹©
        self.statistical_feature_selection()

        # 3. æ¨¡å‹é‡è¦æ€§
        self.model_based_importance()

        # 4. æ’åˆ—é‡è¦æ€§
        self.permutation_importance_analysis()

        # 5. ç¨³å®šæ€§åˆ†æ
        self.feature_stability_analysis()

        # 6. ç»¼åˆæ’å
        self.comprehensive_feature_ranking()

        # 7. ç‰¹å¾é€‰æ‹©å»ºè®®
        recommended_features = self.feature_selection_recommendation(top_k)

        # 8. ç”ŸæˆæŠ¥å‘Š
        self.generate_analysis_report()

        print(f"\nğŸ‰ ç‰¹å¾é‡è¦æ€§åˆ†æå®Œæˆï¼")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {self.analysis_dir}")
        print(f"ğŸ¯ æ¨èä½¿ç”¨TOP {top_k}ç‰¹å¾è¿›è¡Œå»ºæ¨¡")

        return recommended_features


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹ç‰¹å¾é‡è¦æ€§åˆ†æ...")

    # åˆå§‹åŒ–åˆ†æå™¨
    analyzer = FeatureImportanceAnalyzer(
        feature_dir='../outputs/features',
        output_dir='../outputs'
    )

    # åŠ è½½ç‰¹å¾æ–‡ä»¶
    analyzer.load_features()  # è‡ªåŠ¨æ‰¾æœ€æ–°çš„ç‰¹å¾æ–‡ä»¶

    # è¿è¡Œå®Œæ•´åˆ†æ
    recommended_features = analyzer.run_full_analysis(top_k=30)

    print("\nğŸ“Š åˆ†ææ€»ç»“:")
    print(f"ğŸ’¡ æ¨èçš„TOP 30ç‰¹å¾å¯ä»¥æ˜¾è‘—æå‡æ¨¡å‹æ€§èƒ½")
    print(f"ğŸ¯ å»ºè®®åœ¨æ¨¡å‹è®­ç»ƒä¸­ä½¿ç”¨è¿™äº›ç‰¹å¾")
    print(f"ğŸ“ æŸ¥çœ‹ {analyzer.analysis_dir} ç›®å½•è·å–è¯¦ç»†ç»“æœ")